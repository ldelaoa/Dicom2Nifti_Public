{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom as pdcm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>study_date</th>\n",
       "      <th>series_description</th>\n",
       "      <th>study_description</th>\n",
       "      <th>folder_path</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>CT</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>Ave-IP(10) 0%_10%_20%_30%_40%_50%_60%_70%_80%_90%</td>\n",
       "      <td>RTHE CT THORAX</td>\n",
       "      <td>\\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...</td>\n",
       "      <td>unstructured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>CT</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>MM Thorax2,5mm</td>\n",
       "      <td>RTHE CT THORAX</td>\n",
       "      <td>\\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...</td>\n",
       "      <td>unstructured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>RTSTRUCT</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>RS: Unapproved Structure Set</td>\n",
       "      <td>RTHE CT THORAX</td>\n",
       "      <td>\\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...</td>\n",
       "      <td>unstructured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>CT</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>T=0%,PR=95% -&gt; 3%,AR()=26 -&gt; 57</td>\n",
       "      <td>RTHE CT THORAX</td>\n",
       "      <td>\\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...</td>\n",
       "      <td>unstructured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>CT</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>T=10%,PR=5% -&gt; 14%,AR()=37 -&gt; 72</td>\n",
       "      <td>RTHE CT THORAX</td>\n",
       "      <td>\\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...</td>\n",
       "      <td>unstructured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modality  study_date                                 series_description  \\\n",
       "p_id                                                                            \n",
       "4879        CT  2018-07-26  Ave-IP(10) 0%_10%_20%_30%_40%_50%_60%_70%_80%_90%   \n",
       "4879        CT  2018-07-26                                     MM Thorax2,5mm   \n",
       "4879  RTSTRUCT  2018-07-26                       RS: Unapproved Structure Set   \n",
       "4879        CT  2018-07-26                    T=0%,PR=95% -> 3%,AR()=26 -> 57   \n",
       "4879        CT  2018-07-26                   T=10%,PR=5% -> 14%,AR()=37 -> 72   \n",
       "\n",
       "     study_description                                        folder_path  \\\n",
       "p_id                                                                        \n",
       "4879    RTHE CT THORAX  \\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...   \n",
       "4879    RTHE CT THORAX  \\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...   \n",
       "4879    RTHE CT THORAX  \\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...   \n",
       "4879    RTHE CT THORAX  \\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...   \n",
       "4879    RTHE CT THORAX  \\\\zkh\\appdata\\RTDicom\\Projectline - Modelling ...   \n",
       "\n",
       "        datasource  \n",
       "p_id                \n",
       "4879  unstructured  \n",
       "4879  unstructured  \n",
       "4879  unstructured  \n",
       "4879  unstructured  \n",
       "4879  unstructured  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config.yaml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    complete_collection_scans = config['complete_collection_of_scans_per_patient']\n",
    "    endpoints = config['endpoints']\n",
    "    \n",
    "df = pd.read_excel(complete_collection_scans, index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modality               0\n",
       "study_date             0\n",
       "series_description     9\n",
       "study_description     13\n",
       "folder_path            0\n",
       "datasource             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('name not registered', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to take into account scans that were taken before RT. To do this we need to connect the RT date to the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inlc' 'exclude_dosing' 'niet vinden in epic' 'excluded_in_script'\n",
      " 'exclude_concur']\n",
      "n patients in ep_df: 957\n",
      "['inlc' 'exclude_dosing' 'niet vinden in epic' 'excluded_in_script'\n",
      " 'exclude_concur']\n",
      "n patients in ep_df: 957\n"
     ]
    }
   ],
   "source": [
    "# lets remove the excluded patients form this list\n",
    "ep_df = pd.read_excel(endpoints, index_col=1)\n",
    "print(ep_df['Flowchart'].unique())\n",
    "print(f'n patients in ep_df: {len(ep_df)}')\n",
    "\n",
    "clean_ep_df = ep_df[ep_df['Flowchart'] == 'inlc']\n",
    "# lets check that theres no more inlc patients\n",
    "print(ep_df['Flowchart'].unique())\n",
    "print(f'n patients in ep_df: {len(ep_df)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UMCGnr\n",
       "4879      2018-08-06\n",
       "10539     2015-05-18\n",
       "13194     2015-09-10\n",
       "14504     2015-06-22\n",
       "17420     2015-07-06\n",
       "             ...    \n",
       "9935146   2019-07-01\n",
       "9936840   2015-07-13\n",
       "9949900   2015-04-13\n",
       "9970729   2015-05-04\n",
       "9989943   2017-02-01\n",
       "Name: RT_Start_Date, Length: 874, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ep_df.columns[clean_ep_df.columns.str.contains('RT')]\n",
    "RT_startdate = clean_ep_df['RT_Start_Date']\n",
    "RT_startdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_id\n",
       "4879       2018-07-26\n",
       "4879       2018-07-26\n",
       "4879       2018-07-26\n",
       "4879       2018-07-26\n",
       "4879       2018-07-26\n",
       "              ...    \n",
       "9935146    2019-11-19\n",
       "9936840    2015-03-12\n",
       "9936840    2015-03-12\n",
       "9970729    2015-01-26\n",
       "9970729    2015-01-26\n",
       "Name: study_date, Length: 11804, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['study_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, lets merge this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_id\n",
       "2023115    [2014-03-27]\n",
       "2939330    [2013-02-26]\n",
       "4629433    [2013-03-29]\n",
       "6357374    [2013-02-18]\n",
       "7391514    [2014-01-29]\n",
       "Name: study_date, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare the dates, first we need to convert the study date to date time.\n",
    "\n",
    "# df['study_date'] = pd.to_datetime(df['study_date'], format='mixed')\n",
    "# error: Unable to parse datetime string: --, at position 225\n",
    "nodate = df[df['study_date'] == '--'] \n",
    "# so there's a few RTDOSE and RTSTRUCT files that have no study date.\n",
    "# I'm going to fill these with the study date of the scan of these patients.\n",
    "nodate = df.loc[nodate.index].groupby('p_id')['study_date'].unique()\n",
    "nodate = nodate.apply(lambda x: x[1])\n",
    "check_id = nodate.index\n",
    "nodate = zip(nodate.index, nodate.values)\n",
    "\n",
    "for i, date in nodate:\n",
    "    df.loc[i, 'study_date'] = date\n",
    "\n",
    "df.loc[check_id].groupby('p_id')['study_date'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_id\n",
       "4879      2018-07-26\n",
       "4879      2018-07-26\n",
       "4879      2018-07-26\n",
       "4879      2018-07-26\n",
       "4879      2018-07-26\n",
       "             ...    \n",
       "9935146   2019-11-19\n",
       "9936840   2015-03-12\n",
       "9936840   2015-03-12\n",
       "9970729   2015-01-26\n",
       "9970729   2015-01-26\n",
       "Name: study_date, Length: 11804, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['study_date'] = pd.to_datetime(df['study_date'], format='mixed')\n",
    "df['study_date']\n",
    "# 👍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded patients: [210905, 654137, 846557, 849406, 905985, 1092836, 3307795, 3865508, 4850472, 5124665, 5641888, 7417192, 7536975, 9368667]\n",
      "patients with no endpoint: [1234013, 2022493, 2022498, 2730427, 3146700, 5468590, 7391514, 9573899]\n"
     ]
    }
   ],
   "source": [
    "# Lets remove patients that are not in the df from the RT_startdate\n",
    "\n",
    "# RT_startdate.loc[df.index]\n",
    "# KeyError: '[210905, 654137, 846557, 849406, 905985, 1092836, 1234013, 2022493, \n",
    "# 2022498, 2730427, 3146700, 3307795, 3865508, 4850472, 5124665, 5468590, \n",
    "# 5641888, 7391514, 7417192, 7536975, 9368667, 9573899] not in index'\n",
    "\n",
    "# So theres patients that are in the scandataset but not in RT_startdate. \n",
    "# A part of these are excluded patients:\n",
    "excluded_patients = \\\n",
    "    df.index.unique()[(~df.index.unique().isin(clean_ep_df.index.unique())) &\n",
    "                    (df.index.unique().isin(ep_df.index.unique()))]\n",
    "print(f'excluded patients: {excluded_patients.to_list()}')    \n",
    "\n",
    "\n",
    "# Another part of these patients have no endpoint at all:\n",
    "no_endpoint = \\\n",
    "    df.index.unique()[(~df.index.unique().isin(clean_ep_df.index.unique())) &\n",
    "                    (~df.index.unique().isin(ep_df.index.unique()))]\n",
    "\n",
    "print(f'patients with no endpoint: {no_endpoint.tolist()}')\n",
    "\n",
    "# lets safe these for later checking.\n",
    "with open('patient_excultion.txt', 'w') as doc:\n",
    "    doc.write(f'excluded patients: {excluded_patients.to_list()} \\n'\n",
    "              f'patients with no endpoint: {no_endpoint.tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1234013, 2022493, 2022498, 2730427, 3146700, 5468590, 7391514, 9573899] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MenzingaJJ\\OneDrive - UMCG\\Documents\\Code\\data_analysis\\phases_per_patient.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MenzingaJJ/OneDrive%20-%20UMCG/Documents/Code/data_analysis/phases_per_patient.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m not_in_ep \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mdf\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39misin(RT_startdate\u001b[39m.\u001b[39mindex)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MenzingaJJ/OneDrive%20-%20UMCG/Documents/Code/data_analysis/phases_per_patient.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m not_in_ep\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39munique()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MenzingaJJ/OneDrive%20-%20UMCG/Documents/Code/data_analysis/phases_per_patient.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ep_df\u001b[39m.\u001b[39mloc[not_in_ep\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39munique()]\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_iterable(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1334\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MenzingaJJ\\AppData\\Local\\miniconda3\\envs\\ds\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[1234013, 2022493, 2022498, 2730427, 3146700, 5468590, 7391514, 9573899] not in index'"
     ]
    }
   ],
   "source": [
    "# Lets safe these for later checking and remove them from df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
